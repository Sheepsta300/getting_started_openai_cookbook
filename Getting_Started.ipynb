{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1># Getting Started with LangChain and Azure OpenAI in Python Cookbook\n",
    "\n",
    "The purpose of this notebook is to provide a step-by-step guide to getting set up with Azure OpenAI and using available models through the LangChain Framework in Python.  It will explain through examples how to implement models, embeddings, and configure the OpenAI assistant.\n",
    "</h1>"
   ],
   "id": "31d8febc6366de29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ae6c33d6694c468b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Obtaining Keys and Endpoints</h2>",
   "id": "3e40f06503d1123f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To use Azure OpenAI models, you need to obtain API keys and endpoints. You can sign up and create an Azure OpenAI resource using the following link:\n",
    "[Azure Pricing and Purchase Options](https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account)"
   ],
   "id": "74086c9d0653df7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Installing and Importing Dependencies</h2>",
   "id": "35632b3fc39a7984"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- First, install the most current version of LangChain and LangChain_OpenAI.\n",
    "- import libraries."
   ],
   "id": "11f05a5d0ffbd25f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:37:35.348794Z",
     "start_time": "2024-08-05T02:37:28.403684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install langchain\n",
    "!pip install -U langchain langchain_openai\n",
    "!pip install git+https://github.com/organization/langchain_community.git\n"
   ],
   "id": "c0a3b69d7f0db996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (3.10.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain_openai in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (0.1.20)\n",
      "Requirement already satisfied: PyYAML>=5.3 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (3.10.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain_openai) (1.37.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in f:\\pycharm\\ai practice\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain_openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/organization/langchain_community.git\n",
      "  Cloning https://github.com/organization/langchain_community.git to c:\\users\\kyle_\\appdata\\local\\temp\\pip-req-build-7ownf_v5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/organization/langchain_community.git 'C:\\Users\\kyle_\\AppData\\Local\\Temp\\pip-req-build-7ownf_v5'\n",
      "  remote: Repository not found.\n",
      "  fatal: repository 'https://github.com/organization/langchain_community.git/' not found\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  git clone --filter=blob:none --quiet https://github.com/organization/langchain_community.git 'C:\\Users\\kyle_\\AppData\\Local\\Temp\\pip-req-build-7ownf_v5' did not run successfully.\n",
      "  exit code: 128\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "git clone --filter=blob:none --quiet https://github.com/organization/langchain_community.git 'C:\\Users\\kyle_\\AppData\\Local\\Temp\\pip-req-build-7ownf_v5' did not run successfully.\n",
      "exit code: 128\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bfc7bd1475acac69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T05:48:11.661267Z",
     "start_time": "2024-08-04T05:48:11.339720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ],
   "id": "5b920697896c590d",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HumanMessage, SystemMessage\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_openai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AzureChatOpenAI\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'langchain_core'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2c7da13a34ba2e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h4>Set all required Environment Variables</h4>\n",
    "\n",
    "To securely manage your API keys and endpoints, store them in a `.env` file and load them into your application using the `python-dotenv` library.\n",
    "\n",
    "### Step 1: Create a `.env` File\n",
    "\n",
    "Create a file named `.env` in the root directory of your project. Add your Azure OpenAI API key and endpoint to this file:\n",
    "\n",
    "AZURE_OPENAI_API_KEY=your-azure-openai-api-key\n",
    "\n",
    "AZURE_OPENAI_API_ENDPOINT=your-azure-openai-api-endpoint\n",
    "\n",
    "AZURE_API_VERSION=your-api-version\n",
    "\n",
    "Replace `your-azure-openai-api-key`, `your-azure-openai-api-endpoint`, and `your-api-version` with your actual credentials.\n",
    "\n",
    "### Step 2: Install `python-dotenv`\n",
    "\n",
    "Ensure you have the `python-dotenv` library installed. If not, install it using pip:\n",
    "\n",
    "```python\n",
    "!pip install python-dotenv\n"
   ],
   "id": "78cee2ea47ec3a1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>Step 3: Load Environment Variables</h2>\n",
    "Use the following code to load the environment variables from the .env file:"
   ],
   "id": "2bf5a0da65c6e31f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Access the API key and endpoint from environment variables\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "\n",
    "# Verify that the variables are loaded\n",
    "if not openai_api_key or not azure_endpoint or not api_version:\n",
    "    raise ValueError(\"Please ensure the AZURE_OPENAI_API_KEY, AZURE_OPENAI_API_ENDPOINT, and AZURE_API_VERSION environment variables are set\")\n"
   ],
   "id": "4367a6d78df4166c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>Example Usage</h3>\n",
    "Once the environment variables are set and loaded, you can use them in your code. For instance, to create a chat model with Azure OpenAI:"
   ],
   "id": "40dfa97259706063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T23:30:50.617746Z",
     "start_time": "2024-08-04T23:30:50.576210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,  \n",
    "    azure_deployment='gpt-4o',  # Adjust this as per your deployment details\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "print(\"Chat model created successfully.\")\n"
   ],
   "id": "78509a9f76c7ed39",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_openai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AzureChatOpenAI\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m AzureChatOpenAI(\n\u001B[0;32m      4\u001B[0m     openai_api_version\u001B[38;5;241m=\u001B[39mapi_version,  \n\u001B[0;32m      5\u001B[0m     azure_deployment\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpt-4o\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Adjust this as per your deployment details\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     azure_endpoint\u001B[38;5;241m=\u001B[39mazure_endpoint\n\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChat model created successfully.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'langchain_openai'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>Creating a Chat Model</h2>\n",
    "Create a chat model using the `AzureChatOpenAI` class from the LangChain library:"
   ],
   "id": "ffd59243ea2d5b3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ['AZURE_API_VERSION'],  \n",
    "    azure_deployment='gpt-4o',  # Adjust this as per your deployment details\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_API_ENDPOINT']\n",
    ")\n"
   ],
   "id": "edb3cf5fb3d5af16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using Messages from the langchain_core.messages library allows the user to define messages for the model, as well as asign 'roles' to each of the message",
   "id": "5f3f8f3dce1d0085"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from German into English\"),\n",
    "    HumanMessage(content=\"Sie haben gerade Ihr erstes Kunstliche Itelligenz Model erstellt!\"),\n",
    "]"
   ],
   "id": "7175b1b1c425fb3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "response = model.invoke(messages)",
   "id": "d62716de51902a84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "response.content",
   "id": "d6449fbbab472072"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This ensures that your sensitive information like API keys and endpoints are not hard-coded in your notebook but securely managed through environment variables.",
   "id": "4fa4ea94449fa69f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2> Working with Embeddings </h2>\n",
    "Create and use embeddings with the `AzureEmbeddings` class:"
   ],
   "id": "c6a40f9048684197"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T23:49:57.159410Z",
     "start_time": "2024-08-04T23:49:55.207763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of creating embeddings\n",
    "from langchain_openai import AzureEmbeddings\n",
    "import os\n",
    "\n",
    "# Ensure environment variables are set\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "\n",
    "if not openai_api_key or not azure_endpoint:\n",
    "    raise ValueError(\"Please set the AZURE_OPENAI_API_KEY and AZURE_OPENAI_API_ENDPOINT environment variables\")\n",
    "\n",
    "embeddings_model = AzureEmbeddings(\n",
    "    openai_api_key=openai_api_key,\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "texts = [\"Artificial Intelligence is transforming the world.\", \"LangChain is a useful framework for building LLM applications.\"]\n",
    "embeddings = embeddings_model.create_embeddings(texts)\n",
    "print(embeddings)\n"
   ],
   "id": "575706759ecf4b53",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please set the AZURE_OPENAI_API_KEY and AZURE_OPENAI_API_ENDPOINT environment variables",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m azure_endpoint \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAZURE_OPENAI_API_ENDPOINT\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m openai_api_key \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m azure_endpoint:\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease set the AZURE_OPENAI_API_KEY and AZURE_OPENAI_API_ENDPOINT environment variables\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m embeddings_model \u001B[38;5;241m=\u001B[39m AzureEmbeddings(\n\u001B[0;32m     13\u001B[0m     openai_api_key\u001B[38;5;241m=\u001B[39mopenai_api_key,\n\u001B[0;32m     14\u001B[0m     azure_endpoint\u001B[38;5;241m=\u001B[39mazure_endpoint\n\u001B[0;32m     15\u001B[0m )\n\u001B[0;32m     17\u001B[0m texts \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArtificial Intelligence is transforming the world.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLangChain is a useful framework for building LLM applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: Please set the AZURE_OPENAI_API_KEY and AZURE_OPENAI_API_ENDPOINT environment variables"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>Configuring OpenAI Assistant with Azure OpenAI</h2>\n",
    "<h4>Configure and use the OpenAI Assistant with Azure OpenAI:</h4>"
   ],
   "id": "be2fb77233b9405f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "28a42ed860bce09d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistant\n",
    "\n",
    "assistant = OpenAIAssistant(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    version=os.getenv(\"AZURE_API_VERSION\") \n",
    ")\n",
    "\n",
    "response = assistant.ask(\"What is the capital of France?\")\n",
    "print(response)\n"
   ],
   "id": "a02983885b949eb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LangChain Expression Language (LCEL)\n",
    "\n",
    "LangChain Expression Language (LCEL) is a powerful feature that allows developers to easily compose and customize chains of components within LangChain. This chapter introduces LCEL, provides an example of how to use it, and offers best practices for leveraging this feature effectively.\n",
    "\n"
   ],
   "id": "7991d3251f293cf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T00:15:00.087622Z",
     "start_time": "2024-08-05T00:15:00.048758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.chains import SimpleChain  \n",
    "\n",
    "import langchain_core\n",
    "print(dir(langchain_core))\n",
    "\n",
    "# Additional imports based on the notebook examples\n",
    "from langchain_core import LangChain  \n",
    "\n",
    "# Import the LLM and Prompter components\n",
    "from langchain_core.llms import LLM\n",
    "from langchain_core.prompts import Prompter\n",
    "\n",
    "# Define your components\n",
    "llm = LLM(model_name=\"gpt-3.5-turbo\")  # Ensure the model name matches what's available\n",
    "prompter = Prompter(template=\"Translate the following text to French: {input}\")\n",
    "\n",
    "# Compose a chain\n",
    "chain = LangChain(prompter, llm)\n",
    "\n",
    "# Execute the chain with input\n",
    "result = chain.run(input=\"Hello, how are you?\")\n",
    "print(result)\n"
   ],
   "id": "4f46b894d02ac5c5",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimpleChain' from 'langchain.chains' (F:\\pycharm\\ai practice\\.venv\\lib\\site-packages\\langchain\\chains\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchains\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleChain  \n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Additional imports based on the notebook examples\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LangChain  \u001B[38;5;66;03m# For custom chain compositions\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'SimpleChain' from 'langchain.chains' (F:\\pycharm\\ai practice\\.venv\\lib\\site-packages\\langchain\\chains\\__init__.py)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Understanding Memory in LangChain\n",
    "\n",
    "Memory in LangChain is essential for creating dynamic and interactive applications. By using memory, you can create agents that retain context across multiple interactions, making them more intelligent and capable of handling complex tasks. This section explores how to implement and use memory within your LangChain applications.\n"
   ],
   "id": "992d95bfc422236e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:37:48.473505Z",
     "start_time": "2024-08-05T02:37:48.427231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Initialize memory and LLM\n",
    "memory = ConversationBufferMemory()\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "# Create a conversation chain with memory\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# Simulate a conversation\n",
    "response1 = conversation.predict(input=\"What is the capital of France?\")\n",
    "print(response1)\n",
    "\n",
    "response2 = conversation.predict(input=\"Who is the president of France?\")\n",
    "print(response2)\n",
    "\n",
    "# Display memory contents\n",
    "print(\"Conversation History:\")\n",
    "print(memory.load_memory_variables({}))\n"
   ],
   "id": "716aebc1e45f85d6",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmemory\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConversationBufferMemory\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OpenAI\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchains\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConversationChain\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Initialize memory and LLM\u001B[39;00m\n",
      "File \u001B[1;32mF:\\pycharm\\ai practice\\.venv\\lib\\site-packages\\langchain\\llms\\__init__.py:545\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m--> 545\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m llms\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;66;03m# If not in interactive env, raise warning.\u001B[39;00m\n\u001B[0;32m    548\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive_env():\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Stateful Agents\n",
    "\n",
    "LangChain allows you to create agents that can maintain state across multiple interactions. This is particularly useful for chatbots, customer service applications, and any other use case where maintaining context over time is crucial. In this section, we will create a simple stateful agent using LangChain's memory capabilities.\n"
   ],
   "id": "dc51888d142c3925"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents import Agent, ConversationBufferMemory\n",
    "from langchain.llms import OpenAI  # Adjust this import based on your actual LLM class\n",
    "\n",
    "# Initialize memory and LLM\n",
    "memory = ConversationBufferMemory()\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "class StatefulAgent(Agent):\n",
    "    def __init__(self, llm, memory):\n",
    "        self.llm = llm\n",
    "        self.memory = memory\n",
    "\n",
    "    def ask(self, input_text):\n",
    "        # Add user message to memory\n",
    "        self.memory.add_message(\"User\", input_text)\n",
    "        \n",
    "        # Generate response using LLM\n",
    "        response = self.llm.generate(input_text)\n",
    "        \n",
    "        # Add agent's response to memory\n",
    "        self.memory.add_message(\"Agent\", response)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Create an instance of the stateful agent\n",
    "agent = StatefulAgent(llm=llm, memory=memory)\n",
    "\n",
    "# Interact with the agent\n",
    "response1 = agent.ask(\"What is the capital of Germany?\")\n",
    "print(response1)\n",
    "\n",
    "response2 = agent.ask(\"Who is the Chancellor?\")\n",
    "print(response2)\n",
    "\n",
    "# Display the conversation history\n",
    "print(\"Conversation History:\")\n",
    "print(memory.get_memory())\n"
   ],
   "id": "9733a7508234c25d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Best Practices for Memory Management\n",
    "\n",
    "Effective memory management is key to building scalable and efficient applications with LangChain. In this section, we'll cover best practices, including memory pruning, efficient storage techniques, and tips for managing large conversation histories without degrading performance.\n"
   ],
   "id": "bd2b159a310a23de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Practical Example: Building a Customer Support Chatbot\n",
    "\n",
    "In this section, we'll put everything together to build a simple customer support chatbot. The chatbot will maintain a conversation history, allowing it to provide more relevant and contextual responses over time.\n"
   ],
   "id": "73ba461006a119b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Assuming you have the necessary classes and imports\n",
    "class CustomerSupportBot(StatefulAgent):\n",
    "    def handle_query(self, query):\n",
    "        # Handle customer queries with context from previous interactions\n",
    "        response = self.ask(query)\n",
    "        return response\n",
    "\n",
    "# Initialize the customer support bot\n",
    "support_bot = CustomerSupportBot(llm=llm, memory=memory)\n",
    "\n",
    "# Example interaction\n",
    "print(support_bot.handle_query(\"I forgot my password.\"))\n",
    "print(support_bot.handle_query(\"Can you reset it for me?\"))\n",
    "print(support_bot.handle_query(\"What is the status of my last order?\"))\n",
    "\n",
    "# View the conversation history\n",
    "print(\"Full Conversation History:\")\n",
    "print(memory.get_memory())\n"
   ],
   "id": "a9c0652e0c327ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
