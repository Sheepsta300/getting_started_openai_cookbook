{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d808a92c-d36d-4291-a4ad-b12bceb62fec",
   "metadata": {},
   "source": [
    "<h1>Getting Started OpenAi with LangChain in Python Cookbook</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6689d50a-d463-4ad1-8968-180f93bd2f8e",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to give a step by step explanation of how to get set-up with OpenAi and use available models through the LangChain Framework in Python. Furthermore, it will explain through examples how to implement models and available features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8202de6-7d14-44e6-b378-879d26f95ce3",
   "metadata": {},
   "source": [
    "<h2>Obtaining Keys and Endpoints</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21c348-6a01-41d4-9df5-0d1d633367ef",
   "metadata": {},
   "source": [
    "using the link - <a>https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account</a> - one can sign up and create an OpenAI resource, giving access to all needed credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fdf3d-8ebe-48db-bb54-53d7ff195519",
   "metadata": {},
   "source": [
    "<h2>Installing and Importing Dependencies</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a6ef5-202f-4a81-8cbb-da6441808764",
   "metadata": {},
   "source": [
    "- install the most current version of LangChain and LangChain_OpenAi.\n",
    "- import libraries/packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23716db9-d8c8-4682-b662-0de8c185bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "035bd2cf-c045-4cdc-a0d1-f9bf60314f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "import getpass #use getpass for entering any environment variables or keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46149db2-b280-45d5-b910-df1db63040bf",
   "metadata": {},
   "source": [
    "<h4>Set all required Environment Variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaacb02d-3d3b-4b35-a46b-c6b309622482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API_KEY can be set as an environment variable securely like so\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()\n",
    "#os.environ['OPENAI_API_ENDPOINT'] = getpass.getpass()\n",
    "#os.environ['OPENAI_API_VERSION'] = getpass.getpass()\n",
    "#os.environ['COMPLETIONS_MODEL'] = getpass.getpass()\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e595a7e-9b33-472d-96ff-e3229d723642",
   "metadata": {},
   "source": [
    "<h4>Get all required Environment Variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b456baeb-fe51-45c8-940e-7f6ec52da0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "DEPLOYMENT_NAME = os.environ['COMPLETIONS_MODEL']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "ENDPOINT = os.environ['OPENAI_API_ENDPOINT']\n",
    "\n",
    "# The API version required\n",
    "VERSION = os.environ['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b7040-d6ab-4df8-8432-907eb1ca4099",
   "metadata": {},
   "source": [
    "<h2>Creating a Chat Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e4ff3-b3fd-4f10-bd2b-18ac1e259973",
   "metadata": {},
   "source": [
    "- environment variables can be manually passed as parameters\n",
    "- the constuctor can search for environment variables of the corresponding names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b80bbe-442c-4374-a885-87bd6408dc28",
   "metadata": {},
   "source": [
    "Here <b>OPENAI_API_VERSION</b> and <b>OPENAI_API_ENDPOINT</b> are both passed, but <b>OPENAI_API_KEY</b> is being retrieved within the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74baa57a-6b35-403c-9902-2f5a9c7e2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=VERSION,  \n",
    "    azure_deployment=DEPLOYMENT_NAME,\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=60,\n",
    "    max_retries=2,\n",
    "    # organization=\"...\",\n",
    "    # model=\"gpt-35-turbo\",\n",
    "    # model_version=\"0125\",\n",
    "    # other params...\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85766e-2581-4f24-86c1-cde10a0601c0",
   "metadata": {},
   "source": [
    "<h4>Other Optional Parameters</h4>\n",
    "\n",
    "- <b>temperature</b> determines how creative and unpredictable or how deterministic and predictive a model should try to be in it's responses. A temperature of 0 would be predictable and anything higher would become more random.\n",
    "\n",
    "- <b>max_tokens</b> defines the maximum number of tokens (words or pieces of words) the model can generate in its response.\n",
    "\n",
    "- <b>timeout</b> specifies the maximum amount of time (in seconds) to wait for a response from the API before timing out.\n",
    "\n",
    "- <b>max_retries</b> sets the number of times the API request should be retried in case of failure before giving up.\n",
    "\n",
    "- <b>organization</b> is used to specify the organization ID if required for API access.\n",
    "\n",
    "- <b>model</b> specifies the model to be used.\n",
    "\n",
    "- <b>model_version</b> indicates the specific version of the chosen model to use.\n",
    "\n",
    "- Other parameters may be available in differen SDK's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a397b3-27b7-49f0-bccf-108f39196ee6",
   "metadata": {},
   "source": [
    "<h2>Model Usage</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a152eab-52e5-48f3-bc8f-0b410d65c7d0",
   "metadata": {},
   "source": [
    "<h4>Using Messages from the langchain_core.messages library allows the user to define messages for the model, as well as asign 'roles' to each of the message</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c6f2ae-b6d0-46e3-831a-ad5f77daf0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from German into English\"),\n",
    "    HumanMessage(content=\"Sie haben gerade Ihr erstes Kunstliche Itelligenz Model erstellt!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a40126-bede-46dc-8922-8721ac2f9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876d40ef-a75f-4d62-bc0a-43de6b55ce30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have just created your first artificial intelligence model!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a85fe6-ee18-4fc8-88c2-b67297ac8ef8",
   "metadata": {},
   "source": [
    "<h4>Check the costs and token usage of a given model API call</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "561dfbfb-0933-4650-8230-23f1bc2b1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9081591-0b58-44b3-89c7-c3a512f84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from German into English\"),\n",
    "    HumanMessage(content=\"What's the first planet in the Solar System?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9a128-f702-4f48-b695-436629e5ac1a",
   "metadata": {},
   "source": [
    "'get_openai_callback()' is a context manager of the OpenAICallbackHandler class found here - <a>https://github.com/langchain-ai/langchain/blob/a9e637b8f5a8873a8316ef6bf809591dc1f57c09/langchain/callbacks/openai_info.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178153e8-c37c-4ce2-bbb4-15ec6feb58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 65\n",
      "Total prompt tokens: 16\n",
      "Total prompt tokens: 49\n",
      "Total cost (in dollars): $0.000815\n",
      "Total successful requests): 1\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    model.invoke(messages)\n",
    "    print(f\"Total tokens used: {cb.total_tokens}\")\n",
    "    print(f\"Total prompt tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Total prompt tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total cost (in dollars): ${cb.total_cost}\")\n",
    "    print(f\"Total successful requests): {cb.successful_requests}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82390d-bdc4-4b92-bb52-77580cca48f9",
   "metadata": {},
   "source": [
    "<h4>Async model usage</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "089dc929-599b-46a7-8882-3c1f3bed190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Give a two sentance explanation of the following python code\"),\n",
    "    HumanMessage(content=\"await model.ainvoke(messages)\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44ccd78b-47e7-462e-8bf0-8c00899c4ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This Python code asynchronously invokes a method `ainvoke` on the `model` object, passing `messages` as an argument. It uses the `await` keyword, indicating that it is part of an asynchronous function and that it will pause execution until the `ainvoke` method completes.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await model.ainvoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9705c6-0512-48b3-b117-8e1bc385cf86",
   "metadata": {},
   "source": [
    "<h2>Tools and Structured output</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62770fa-c0e4-45ad-8f3b-5fd64e835857",
   "metadata": {},
   "source": [
    "Import the required packages. BaseModel is a parent class that all tools will inherit from, and Field is what all properties of the tool will be defined as. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84527cdd-6d45-4d18-a3c4-887a8537c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b68b06-ccd1-40f1-9201-9814de191254",
   "metadata": {},
   "source": [
    "Tools are essentially classes that can be passed to a chosen model to influence/structure how the response should be formatted or generated.\n",
    "\n",
    "<b>For example:</b>\n",
    "\n",
    "- A Weather tool with a specific API call could be passed so the model knows to use this specific API for data retrieval.\n",
    "- A City tool with fields like population, size, main_language so the model can return any city related queries with an object containing the corresponding filled fields.\n",
    "- An Image tool with a url field to be returned when asked to search for an image containing a dog with the field containing the url of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "05f0ff77-07bd-4041-9ab5-c2ba13ca644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "#adds the ability to make a field Optional [NULL]\n",
    "\n",
    "class Person(BaseModel):\n",
    "    '''Information about a given person'''\n",
    "\n",
    "    name: str = Field(..., description=\"The name of a person\")\n",
    "    alive: bool = Field(..., description=\"Thether the person is alive or not\")\n",
    "    profession: str = Field(..., description=\"What the person does for work or professionally\")\n",
    "    noteable_features: str = Field(..., description=\"Any noteworthy features/achievements about the person\")\n",
    "    hobbies: Optional[str] = Field(description=\"Anything hobbies the person may have\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5d9b7cc-d127-4f28-ab8f-829f236ef419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Kate Sheppard', alive=False, profession='Suffragist', noteable_features=\"Leader of the women's suffrage movement in New Zealand, instrumental in making New Zealand the first country to grant women the right to vote in 1893.\", hobbies=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(Person)\n",
    "response = structured_model.invoke(\"Tell me about Kate Sheppard\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb76bf-283c-4095-aa33-27e772f09292",
   "metadata": {},
   "source": [
    "<h5>As the response of the invocation has been structured using the Person tool, the response can be accessed like a Person object.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "63f05dc8-7832-429c-b710-ceb72a56b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kate Sheppard\n",
      "False\n",
      "Suffragist\n",
      "She was the most prominent member of New Zealand's women's suffrage movement and is widely credited with making New Zealand the first country to grant women the right to vote in 1893.\n"
     ]
    }
   ],
   "source": [
    "print(response.name)\n",
    "print(response.alive)\n",
    "print(response.profession)\n",
    "print(response.noteable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5247e4-c810-4a61-98ee-9534ae10d300",
   "metadata": {},
   "source": [
    "<h4>JSON</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350506c9-8d59-43c5-a5ba-cc2493da2faf",
   "metadata": {},
   "source": [
    "Models can also be explicitly told to respond in a JSON structured format. This could then be used for future API calls or simply easier access of information. However, <b>the word \"json\" must be included in the message string.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "42478d15-0aa2-4e47-b279-e807397d9f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Alexandra Johnson\",\\n  \"alive\": true,\\n  \"profession\": \"Software Engineer\"\\n}'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_model = model.bind(response_format={\"type\": \"json_object\"})\n",
    "\n",
    "response = json_model.invoke(\n",
    "    '''Return a JSON object of a random person with features like name,\n",
    "    alive (if they're alive or not) and their profession.''' \n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35208928-b640-4b77-9640-0b8f12b2924f",
   "metadata": {},
   "source": [
    "The response can then be formatted into JSON object and accessed using normal JSON notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c59bbe45-28c7-4aba-abfc-9d5e63aac3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Alexandra Johnson', 'alive': True, 'profession': 'Software Engineer'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = json.loads(response.content)\n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b4a4c-b435-40d1-9145-3918661fff7d",
   "metadata": {},
   "source": [
    "<h2>File input</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d150455-42c3-4943-89fa-d916ef76060b",
   "metadata": {},
   "source": [
    "Models can be fed files of various forms as their inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0824799-7ec2-48f1-96e5-c1be1c95a8de",
   "metadata": {},
   "source": [
    "<h4>Images</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54937c-eae4-4adc-be21-3779b6281e01",
   "metadata": {},
   "source": [
    "Import the required libraries to allow for HTTP requests and file conversion.\n",
    "\n",
    "Make sure the file format is correct otherwise a File not found error will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ebd83bd8-da43-4c2b-a07f-a1bd0ecd0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import httpx\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/b/bf/Aoraki_Mount_Cook.JPG\"\n",
    "\n",
    "# use an HTTP get request to retrieve the binary image data\n",
    "binary_image_data = httpx.get(url).content\n",
    "\n",
    "# encode the binary_image_data into base 64 so that it's in bytes\n",
    "# this allows it to be transmitted in JSON or text format\n",
    "byte_image_data = base64.b64encode(binary_image_data)\n",
    "\n",
    "# decode the data into UTF-8 to allow for to make the data workable\n",
    "# web applications and models require it in a workable format\n",
    "# UTF-8 is a fairly standardised format\n",
    "image_data = byte_image_data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fdb153be-bcb0-4a61-902a-3394cfb1206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image depicts a stunning mountain landscape with snow-covered peaks. The mountains are reflected beautifully in a calm, clear lake in the foreground, creating a mirror-like effect. The sky is mostly clear with a few scattered clouds, and the overall scene is serene and picturesque. The rocky shoreline of the lake is visible in the foreground, adding to the natural beauty of the location. The combination of the snow-capped mountains, clear lake, and blue sky creates a breathtaking and tranquil environment.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [  \n",
    "    SystemMessage(content=[{\"type\": \"text\", \"text\": \"describe the image location\"}]),\n",
    "    HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ]\n",
    "    )\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
