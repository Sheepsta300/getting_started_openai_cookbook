{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d808a92c-d36d-4291-a4ad-b12bceb62fec",
   "metadata": {},
   "source": [
    "<h1>Getting Started OpenAi with LangChain in Python Cookbook</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6689d50a-d463-4ad1-8968-180f93bd2f8e",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to give a step by step explanation of how to get set-up with OpenAi and use available models through the LangChain Framework in Python. Furthermore, it will explain through examples how to implement models and available features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8202de6-7d14-44e6-b378-879d26f95ce3",
   "metadata": {},
   "source": [
    "<h2>Obtaining Keys and Endpoints</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21c348-6a01-41d4-9df5-0d1d633367ef",
   "metadata": {},
   "source": [
    "using the link - <a>https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account</a> - one can sign up and create an OpenAI resource, giving access to all needed credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61b81a-5c29-4da1-818f-fe3c2b1f9280",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Installing and Importing Dependencies\n",
    "-   Microsoft [recommend](https://github.com/microsoft/vscode-jupyter/wiki/Installing-Python-packages-in-Jupyter-Notebooks) to use %pip for installing for vscode .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23716db9-d8c8-4682-b662-0de8c185bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a6ef5-202f-4a81-8cbb-da6441808764",
   "metadata": {},
   "source": [
    "- install the most current version of LangChain and LangChain_OpenAi.\n",
    "- import libraries/packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035bd2cf-c045-4cdc-a0d1-f9bf60314f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "import getpass #use getpass for entering any environment variables or keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46149db2-b280-45d5-b910-df1db63040bf",
   "metadata": {},
   "source": [
    "<h4>Set all required Environment Variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf509fb-e2de-4b4c-9c55-35202af8287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API_KEY can be set as an environment variable securely like so\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = getpass.getpass()\n",
    "#os.environ['AZURE_OPENAI_API_ENDPOINT'] = getpass.getpass()\n",
    "#os.environ['AZURE_OPENAI_API_VERSION'] = getpass.getpass()\n",
    "#os.environ['COMPLETIONS_MODEL'] = getpass.getpass()\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e595a7e-9b33-472d-96ff-e3229d723642",
   "metadata": {},
   "source": [
    "<h4>Get all required Environment Variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b456baeb-fe51-45c8-940e-7f6ec52da0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "DEPLOYMENT_NAME = os.environ['COMPLETIONS_MODEL']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "API_KEY = os.environ['AZURE_OPENAI_API_KEY']\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "ENDPOINT = os.environ['AZURE_OPENAI_API_ENDPOINT']\n",
    "\n",
    "# The API version required\n",
    "VERSION = os.environ['AZURE_OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b7040-d6ab-4df8-8432-907eb1ca4099",
   "metadata": {},
   "source": [
    "<h2>Creating an AzureChatOpenAI Model</h2>\n",
    "\n",
    "-   LangChain's AzureChatOpenAI Info  [Integration Overview](https://python.langchain.com/v0.2/docs/integrations/chat/azure_chat_openai/) | [API Reference](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b80bbe-442c-4374-a885-87bd6408dc28",
   "metadata": {},
   "source": [
    "Here <b>OPENAI_API_VERSION</b> and <b>OPENAI_API_ENDPOINT</b> are both passed, but <b>OPENAI_API_KEY</b> is being retrieved within the constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e4ff3-b3fd-4f10-bd2b-18ac1e259973",
   "metadata": {},
   "source": [
    "- environment variables can be manually passed as parameters\n",
    "- the constuctor can search for environment variables of the corresponding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74baa57a-6b35-403c-9902-2f5a9c7e2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=VERSION,  \n",
    "    azure_deployment=DEPLOYMENT_NAME,\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=60,\n",
    "    max_retries=2,\n",
    "    # organization=\"...\",\n",
    "    # model=\"gpt-35-turbo\",\n",
    "    # model_version=\"0125\",\n",
    "    # other params...\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85766e-2581-4f24-86c1-cde10a0601c0",
   "metadata": {},
   "source": [
    "<h4>Other Optional Parameters</h4>\n",
    "\n",
    "- <b>temperature</b> determines how creative and unpredictable or how deterministic and predictive a model should try to be in it's responses. A temperature of 0 would be predictable and anything higher would become more random.\n",
    "\n",
    "- <b>max_tokens</b> defines the maximum number of tokens (words or pieces of words) the model can generate in its response.\n",
    "\n",
    "- <b>timeout</b> specifies the maximum amount of time (in seconds) to wait for a response from the API before timing out.\n",
    "\n",
    "- <b>max_retries</b> sets the number of times the API request should be retried in case of failure before giving up.\n",
    "\n",
    "- <b>organization</b> is used to specify the organization ID if required for API access.\n",
    "\n",
    "- <b>model</b> specifies the model to be used.\n",
    "\n",
    "- <b>model_version</b> indicates the specific version of the chosen model to use.\n",
    "\n",
    "- Other parameters may be available in differen SDK's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a397b3-27b7-49f0-bccf-108f39196ee6",
   "metadata": {},
   "source": [
    "<h2>Model Usage</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a152eab-52e5-48f3-bc8f-0b410d65c7d0",
   "metadata": {},
   "source": [
    "<h4>Using Messages from the langchain_core.messages library allows the user to define messages for the model, as well as asign 'roles' to each of the message</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a462a-4a83-4f17-a337-be04d67d3020",
   "metadata": {},
   "source": [
    "-   LangChain compatible chat models take a list of `messages` as `input` and returns the AI message as `output`. \n",
    "-   All messages have `role` and `content` property. However, the roles here are being set by the use of `SystemMessage` and `HumanMessage`. We'll cover more on this later.\n",
    "-   Additional provider-specific information can be incomporated using the `Additional Properties`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c6f2ae-b6d0-46e3-831a-ad5f77daf0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from German into English\"),\n",
    "    HumanMessage(content=\"Sie haben gerade Ihr erstes Kunstliche Itelligenz Model erstellt!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a40126-bede-46dc-8922-8721ac2f9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "876d40ef-a75f-4d62-bc0a-43de6b55ce30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have just created your first artificial intelligence model!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9f2e3-6eac-41d5-a959-f1f931c1029a",
   "metadata": {},
   "source": [
    "### Prompting\r\n",
    "-   Prompts are the inputs to language models, refined from raw user inputs to be ready for processing by the models.\r\n",
    "-   [Prompting](https://www.datacamp.com/tutorial/prompt-engineering-with-langchain) involves crafting text inputs that clearly communicate with the models outlining the specific task we want it to accomplish.  \r\n",
    "This can include:\r\n",
    "    - selecting the appropriate wording and setting a particular tone or style,\r\n",
    "    - providing necessary context\r\n",
    "    - assigning a role to it, such as asking it to respond as if it were a native speaker of a certain language.\r\n",
    "-   `PromptTemplate` is used to create an instance of [prompt](https://python.langchain.com/v0.1/docs/expression_language/get_started/#1-prompt) and this is `invoked` by sending this to a model and this produces a `PromptValue`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1732bc5-2640-4e97-8830-b2bb4b838bea",
   "metadata": {},
   "source": [
    "#### Prompt Templates\n",
    "-   LangChain allows developers to design parameterised [**prompt templates**](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/) that are reusable and easilly transferrable between different models for integration.\n",
    "-   It takes user input and inserts said input into the prompt to feed into the language models.\n",
    "\n",
    "#### `PromptTemplate`  \n",
    "The example code uses `.from_template` which handles a single string template with placeholders for dynamic inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04a11bb8-e4d9-4687-ab89-210aa1b7b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate  \n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"What vege crops can I grow in {month} in {city}, New Zealand?\"\n",
    ")\n",
    "\n",
    "prompt_value = prompt_template.format(month = \"December\", city = \"Rotorua\")\n",
    "\n",
    "# print(prompt_template) # <- uncomment to see\n",
    "# print(prompt_value) # <- uncomment to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f92db0c1-3741-42be-9d1e-edbe5010b61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Rotorua, New Zealand, December falls at the start of summer, which is a great time for growing a variety of vegetables. Here are some vegetable crops you can consider planting in December:\\n\\n1. **To'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt_value)\n",
    "response.content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d565e4d-4f33-4752-8d8c-8e0abb0b0380",
   "metadata": {},
   "source": [
    "#### `ChatPromptTemplate`  \r",
    "This  is optimised for conversation like format. The prompt is a list of chat messages. Each chat message is associated with `role` and `content`. In the example code `.from_messages` is used to include multiple messgaes\n",
    "\n",
    "Here we will hardcode roles in the chat prompt, as opposed to using `SystemMessage` or `HumanMessage` like earlier.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46e869bf-370d-4742-837f-c7d5eb76a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "                    You are a travel agent helping customers plan their trips.\n",
    "                    Recommend them regarding popular Accommodation, Food and Activities of the country customer is asking.\n",
    "                    \"\"\"), \n",
    "        (\"ai\", \"Hi there, What can I help you with today?\"),\n",
    "        (\"human\", \"Hi I'm {name}, I'm planning a trip to {country}. Any recommendations\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = chat_template.format_messages(name=\"Lucy\", country=\"New Zealand\")\n",
    "\n",
    "# print(chat_template) # <- uncomment to see\n",
    "# print(prompt_value) # <- uncomment to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c87adc53-1248-441d-aa46-44f410c24796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Lucy! New Zealand is a fantastic destination with stunning landscapes, rich culture, and plenty of activities to keep you entertained. Here are some recommendations for your trip:\\n\\n### Accommodation\\n1. **Auckland:**\\n   - **SkyCity Hotel:** Located in the heart of the city, close to major attractions.\\n   - **Cordis, Auckland:** A luxurious option with excellent amenities.\\n\\n2. **Queenstown:**\\n   - **Eichardt's Private Hotel:** A luxury hotel with breathtaking views of Lake Wakatipu.\\n   - **The Rees Hotel:** Offers a mix of hotel rooms and apartments with stunning lake views.\\n\\n3. **Rotorua:**\\n   - **Solitaire Lodge:** A luxury lodge offering stunning lake views and fine dining.\\n   - **Regent of Rotorua:** A boutique hotel with modern amenities.\\n\\n### Food\\n1. **Auckland:**\\n   - **Depot Eatery & Oyster Bar:** Known for its fresh seafood and casual vibe.\\n   - **Clooney:** Offers a fine dining experience with contemporary New Zealand cuisine.\\n\\n2. **Wellington:**\\n   - **Logan Brown:** A fine\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt_value)\n",
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc70e63-388c-45f1-b4dc-93a16b8eea31",
   "metadata": {},
   "source": [
    "#### Assigning Roles Using LangChain Messages\n",
    "Compared to hardcoding the roles like above, LangChain Messages allow for more flexibility and better management especially with complex conversations with multiple roles involved. It also simplifies the visualization of the conversation flow.\n",
    "\n",
    "It is therefore recommended to use LangChain messages where possible.\n",
    "   \n",
    "**Basic Message Types**\n",
    "\n",
    "|             |          |\n",
    "|-------------|----------|\n",
    "| SystemMessage | Set how the AI should behave (appropriate wording, tone, style etc) |\n",
    "| HumanMessage | Message sent from the user |\n",
    "| AIMessage | Message from the AI chat model (context setting, guidance for response) |  \n",
    "      \n",
    "for more info [Message Types](https://python.langchain.com/v0.1/docs/modules/model_io/chat/message_types/) | [API Reference](https://api.python.langchain.com/en/latest/core_api_reference.html#module-langchain_core.messages) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95152680-ebc2-4106-99bf-679547d0d1fe",
   "metadata": {},
   "source": [
    "#### `base message` and `MessagePromptTemplate`\n",
    "We can also pass a `base message` or `MessagePromptTemplate` instead of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b956d584-881a-4e9b-ae81-565ffdd7bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\"You are a translator. You are to translate the text into English.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = chat_template.format_messages(text=\"アサヒスーパードライは日本のビールのです。\")\n",
    "\n",
    "# print(chat_template) # <- uncomment to see\n",
    "# print(prompt_value) # <- uncomment to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "648579a0-ca55-4885-bf70-47c0e08e066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Asahi Super Dry is a Japanese beer.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt_value)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f05d01-151b-4cda-a386-567a5523bb03",
   "metadata": {},
   "source": [
    "#### `MessagePlaceHolder`\n",
    "This  is used to select which messages to include when formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0f7c266b-4438-4912-9b21-b0611960f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    AIMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# SYSTEM ROLE Prompt\n",
    "system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "                                            You are a precise assistant who knows the shcedule of the team.\n",
    "                                            Schedule details are as follows: {schedule}.\n",
    "                                            Only provide information to the team members.\n",
    "                                            Strictly only provide information specific to what is asked, Do not give extra information.\n",
    "                                            \"\"\")\n",
    "# HUMAN ROLE Prompt\n",
    "human_template = HumanMessagePromptTemplate.from_template(\"My name is {user_name}.\")\n",
    "# AI ROLE Prompt\n",
    "ai_template = AIMessagePromptTemplate.from_template(\"Hello {user_name}, how can I help you today?\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # this has essentially created a 'conversation history'\n",
    "        system_template,\n",
    "        human_template,\n",
    "        ai_template,\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"), \n",
    "    ]\n",
    ")\n",
    "\n",
    "# print(chat_prompt) # <- uncomment to see the chat prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8c223-97d6-4a5c-83a5-24eeba7c47f3",
   "metadata": {},
   "source": [
    "We can then input more prompts which will take the `MessagePlaceholders` place and create line of sentances, or a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cea2fce5-2692-4df1-bac1-80bb9472d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    " from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "schedule = \"\"\"\n",
    "    Team Members: Alice, Bob, Carol, David, Emily\n",
    "    Team Meeting Schedule: Every Tuesday at 11:00 AM\n",
    "    Topic: LangChain with Azure OpenAI Integration\n",
    "\"\"\"\n",
    "# these messages will take MESSAGEPLACEHOLDERS place\n",
    "human_query = HumanMessage(\"When is the next team meeting and who is attending?\")\n",
    "ai_message = AIMessage(\"Hold on a second, let me check the schedule for you.\")\n",
    "\n",
    "prompt_value = chat_prompt.format_messages(\n",
    "    conversation=[human_query, ai_message], user_name=\"David\", schedule=schedule\n",
    ")\n",
    "\n",
    "# print(prompt_value) # <- uncomment to see the prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1558cfbf-5806-4a24-a0fa-8a1fb90a00d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next team meeting is on Tuesday at 11:00 AM. The attendees are Alice, Bob, Carol, David, and Emily.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt_value)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec2ed1-83f1-4331-97fb-a6319f53e1fd",
   "metadata": {},
   "source": [
    "#### `FewShotPrompt`\n",
    "We can use examples (shots) to condition the model for a better response by including some example input and output in the prompt. It will tell the model about the context and how we want the output to be formatted.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fcaa0701-6f2c-4ffb-b011-75b6849d2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency Unit Conversion: [Input] one dollar => [Output] $1\n",
      "Currency Unit Conversion: [Input] one hundred yen => [Output] ¥100\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"one dollar\", \"output\": \"$1\"},\n",
    "    {\"input\": \"thirty five euros\", \"output\": \"€35\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"], template=\"Currency Unit Conversion: [Input] {input} => [Output] {output}\"\n",
    ")\n",
    "\n",
    "# unpack the first example dictionary and feed it to the prompt template to format\n",
    "print(example_prompt.format(**examples[0]))\n",
    "\n",
    "# feed examples to FewShotPromptTemplate to generate a final prompt\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix= \"Convert the currency units: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "prompt_value= fewshot_prompt.format(input=\"one hundred yen\")\n",
    "\n",
    "response = model.invoke(prompt_value)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b27f1-90a9-46c7-8a43-a8ae356235ef",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "-   Many LangChain components implement the [**runnable**](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface) protocol which allows them to be easily chained together. These components can be combined together in a sequence of calls which we call them a chain.\n",
    "\n",
    "-   Chaining `Runnables` in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7bfdc351-1901-4fc4-bceb-067a68b54a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "    You are an expert in {country} cuisine. \n",
    "    Keep it simple and short.\n",
    "    \"\"\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "         system_template,\n",
    "        (\"human\", \"I'd like to find out about {country} cuisine.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6682cc-576c-45f0-8b5b-52674a0f30a8",
   "metadata": {},
   "source": [
    "This is how we have been using prompts but now will skip this step and invoke using the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "761b48c5-92e5-4857-b280-cdd486c29b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Japan, the most popular sashimi is often maguro (tuna), particularly the fatty cuts like otoro. Globally, salmon sashimi tends to be more popular due to its rich flavor and buttery texture.'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value = chat_prompt.format_messages(country=\"Japanese\", question=\"What is the most popular Sashimi in Japan vs the rest of the world?\")\n",
    "\n",
    "response = model.invoke(prompt_value)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3893edc8-acc0-418e-ac5d-31a65b00b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Japan, the most popular sashimi is often maguro (tuna), particularly the fatty part known as toro. Globally, salmon sashimi tends to be more popular due to its rich flavor and widespread availability.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = chat_prompt | model | StrOutputParser()\n",
    "\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\n",
    "            \"country\": \"Japanese\", \n",
    "            \"question\": \"What is the most popular Sashimi in Japan vs the rest of the world?\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a85fe6-ee18-4fc8-88c2-b67297ac8ef8",
   "metadata": {},
   "source": [
    "<h4>Check the costs and token usage of a given model API call</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "561dfbfb-0933-4650-8230-23f1bc2b1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9081591-0b58-44b3-89c7-c3a512f84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from German into English\"),\n",
    "    HumanMessage(content=\"What's the first planet in the Solar System?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9a128-f702-4f48-b695-436629e5ac1a",
   "metadata": {},
   "source": [
    "'get_openai_callback()' is a context manager of the OpenAICallbackHandler class found here - <a>https://github.com/langchain-ai/langchain/blob/a9e637b8f5a8873a8316ef6bf809591dc1f57c09/langchain/callbacks/openai_info.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "178153e8-c37c-4ce2-bbb4-15ec6feb58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 37\n",
      "Total prompt tokens: 27\n",
      "Total prompt tokens: 10\n",
      "Total cost (in dollars): $0.000285\n",
      "Total successful requests): 1\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    model.invoke(messages)\n",
    "    print(f\"Total tokens used: {cb.total_tokens}\")\n",
    "    print(f\"Total prompt tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Total prompt tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total cost (in dollars): ${cb.total_cost}\")\n",
    "    print(f\"Total successful requests): {cb.successful_requests}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82390d-bdc4-4b92-bb52-77580cca48f9",
   "metadata": {},
   "source": [
    "<h4>Async model usage</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "089dc929-599b-46a7-8882-3c1f3bed190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Give a two sentance explanation of the following python code\"),\n",
    "    HumanMessage(content=\"await model.ainvoke(messages)\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44ccd78b-47e7-462e-8bf0-8c00899c4ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This Python code snippet uses the `await` keyword to asynchronously call the `ainvoke` method on the `model` object with `messages` as its argument. The `await` keyword indicates that the code execution will pause until the `ainvoke` method completes, allowing other tasks to run concurrently.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await model.ainvoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9705c6-0512-48b3-b117-8e1bc385cf86",
   "metadata": {},
   "source": [
    "<h2>Tools and Structured output</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62770fa-c0e4-45ad-8f3b-5fd64e835857",
   "metadata": {},
   "source": [
    "Import the required packages. BaseModel is a parent class that all tools will inherit from, and Field is what all properties of the tool will be defined as. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84527cdd-6d45-4d18-a3c4-887a8537c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b68b06-ccd1-40f1-9201-9814de191254",
   "metadata": {},
   "source": [
    "Tools are essentially classes that can be passed to a chosen model to influence/structure how the response should be formatted or generated.\n",
    "\n",
    "<b>For example:</b>\n",
    "\n",
    "- A Weather tool with a specific API call could be passed so the model knows to use this specific API for data retrieval.\n",
    "- A City tool with fields like population, size, main_language so the model can return any city related queries with an object containing the corresponding filled fields.\n",
    "- An Image tool with a url field to be returned when asked to search for an image containing a dog with the field containing the url of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05f0ff77-07bd-4041-9ab5-c2ba13ca644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "#adds the ability to make a field Optional [NULL]\n",
    "\n",
    "class Person(BaseModel):\n",
    "    '''Information about a given person'''\n",
    "\n",
    "    name: str = Field(..., description=\"The name of a person\")\n",
    "    alive: bool = Field(..., description=\"Thether the person is alive or not\")\n",
    "    profession: str = Field(..., description=\"What the person does for work or professionally\")\n",
    "    noteable_features: str = Field(..., description=\"Any noteworthy features/achievements about the person\")\n",
    "    hobbies: Optional[str] = Field(description=\"Anything hobbies the person may have\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5d9b7cc-d127-4f28-ab8f-829f236ef419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Kate Sheppard', alive=False, profession='Suffragist', noteable_features=\"Leader of the women's suffrage movement in New Zealand, instrumental in making New Zealand the first country to grant women the right to vote in 1893.\", hobbies=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(Person)\n",
    "response = structured_model.invoke(\"Tell me about Kate Sheppard\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb76bf-283c-4095-aa33-27e772f09292",
   "metadata": {},
   "source": [
    "<h5>As the response of the invocation has been structured using the Person tool, the response can be accessed like a Person object.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63f05dc8-7832-429c-b710-ceb72a56b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kate Sheppard\n",
      "False\n",
      "Suffragist\n",
      "Leader of the women's suffrage movement in New Zealand, instrumental in making New Zealand the first country to grant women the right to vote in 1893.\n"
     ]
    }
   ],
   "source": [
    "print(response.name)\n",
    "print(response.alive)\n",
    "print(response.profession)\n",
    "print(response.noteable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5247e4-c810-4a61-98ee-9534ae10d300",
   "metadata": {},
   "source": [
    "<h4>JSON</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350506c9-8d59-43c5-a5ba-cc2493da2faf",
   "metadata": {},
   "source": [
    "Models can also be explicitly told to respond in a JSON structured format. This could then be used for future API calls or simply easier access of information. However, <b>the word \"json\" must be included in the message string.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42478d15-0aa2-4e47-b279-e807397d9f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Jane Doe\",\\n  \"alive\": true,\\n  \"profession\": \"Software Engineer\"\\n}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_model = model.bind(response_format={\"type\": \"json_object\"})\n",
    "\n",
    "response = json_model.invoke(\n",
    "    '''Return a JSON object of a random person with features like name,\n",
    "    alive (if they're alive or not) and their profession.''' \n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35208928-b640-4b77-9640-0b8f12b2924f",
   "metadata": {},
   "source": [
    "The response can then be formatted into JSON object and accessed using normal JSON notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c59bbe45-28c7-4aba-abfc-9d5e63aac3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Jane Doe', 'alive': True, 'profession': 'Software Engineer'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = json.loads(response.content)\n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b4a4c-b435-40d1-9145-3918661fff7d",
   "metadata": {},
   "source": [
    "<h2>File input</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d150455-42c3-4943-89fa-d916ef76060b",
   "metadata": {},
   "source": [
    "Models can be fed files of various forms as their inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0824799-7ec2-48f1-96e5-c1be1c95a8de",
   "metadata": {},
   "source": [
    "<h4>Images</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54937c-eae4-4adc-be21-3779b6281e01",
   "metadata": {},
   "source": [
    "Import the required libraries to allow for HTTP requests and file conversion.\n",
    "\n",
    "- Make sure the file format is correct otherwise a File not found error will be thrown.\n",
    "\n",
    "- Ensure the HTTP request was successful with a 200 response code otherwise a 404 error will be thrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebd83bd8-da43-4c2b-a07f-a1bd0ecd0d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status code is: 200\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import httpx\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/b/bf/Aoraki_Mount_Cook.JPG\"\n",
    "\n",
    "# Use an HTTP get request to retrieve the image\n",
    "response = httpx.get(url)\n",
    "\n",
    "# Check the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Extract the binary image data\n",
    "    binary_image_data = response.content\n",
    "\n",
    "    # Encode the binary_image_data into base 64 so that it's in bytes\n",
    "    # This allows it to be transmitted in JSON or text format\n",
    "    byte_image_data = base64.b64encode(binary_image_data)\n",
    "\n",
    "    # Decode the data into UTF-8 to allow for to make the data workable\n",
    "    # Web applications and models require it in a workable format\n",
    "    # UTF-8 is a fairly standardised format\n",
    "    image_data = byte_image_data.decode(\"utf-8\")\n",
    "\n",
    "print(f'The status code is: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f20898-73d6-4fed-9433-bb086019f1a7",
   "metadata": {},
   "source": [
    "When using data of different types, such as text in the SystemMessage and a file in the HumanMessage, it's necessary to specify a type header so the model knows how to interpret the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdb153be-bcb0-4a61-902a-3394cfb1206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This image depicts a stunning mountainous landscape with a snow-capped peak reflected in a calm, clear lake. The mountains are rugged and covered in snow, suggesting a cold and possibly remote location. The clear blue sky and the reflection in the water add to the serene and picturesque quality of the scene. The foreground features some rocks along the edge of the lake, enhancing the natural beauty of the setting. This type of scenery is often found in high-altitude regions, such as the Himalayas, the Alps, or the Southern Alps in New Zealand.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [  \n",
    "    SystemMessage(content=[{\"type\": \"text\", \"text\": \"describe the image location\"}]),\n",
    "    HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ]\n",
    "    )\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e97f80-aa24-4ff8-af52-0f5b955a2090",
   "metadata": {},
   "source": [
    "<h4>Audio</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44d1e7-7051-411b-8f9d-65f6548bb1a0",
   "metadata": {},
   "source": [
    "Chat completion models are somewhat limited in how they work with audio files. Audio files cannot be transmitted to the model directly, but instead must be transcribed using the <b>Whisper API</b>. The transcribed text can then be used with a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fcba8-2d47-40ff-84c2-079250568a6e",
   "metadata": {},
   "source": [
    "The whisper API can currently only be access through openai services direct, there is no langchain support for them at the moment. Therefore, the OpenAI library must be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc1f2f70-b45e-4bdb-bc62-d723a3c3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54d528-ab04-4a8e-ba0a-7617d31ab01c",
   "metadata": {},
   "source": [
    " URL of the audio file to be retrieved\n",
    "audio_url = \"https://www.doc.govt.nz/globalassets/documents/conservation/native-animals/birds/bird-song/takahe-song-10.mp3\"\n",
    "\n",
    " Use an HTTP GET request to retrieve the audio data\n",
    "audio_test_file = httpx.get(audio_url).content\n",
    "\n",
    "#byte_audio_data = base64.b64encode(binary_audio_data)\n",
    "    \n",
    " Decode the base64 data into a UTF-8 string\n",
    "#audio_test_file = byte_audio_data.decode(\"utf-8\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],  \n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    azure_endpoint = os.environ[\"OPENAI_API_ENDPOINT\"]\n",
    ")\n",
    "    \n",
    "deployment_id = os.environ[\"COMPLETIONS_MODEL\"] #This will correspond to the custom name you chose for your deployment when you deployed a model.\"\n",
    "#audio_test_file = \"Real_Estate_Audio.mp3\"\n",
    "    \n",
    "result = client.audio.transcriptions.create(\n",
    "    file=audio_test_file,            \n",
    "    model='<WHISPER_MODEL'>\n",
    ")\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252aad1-9309-48a9-bc5b-8d83bd652586",
   "metadata": {},
   "source": [
    "<h4>Azure Cognitive Services</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea377a32-af7d-4dca-9ab4-15c241e6e867",
   "metadata": {},
   "source": [
    "Azure Cognitive Services come as a toolkit, that means it's bundled together as one package. Contained within are:\n",
    "- Azure Cognitive Services Image Analysis\n",
    "  \n",
    "- Azure Cognitive Services Form Recognizer\n",
    "  \n",
    "- Azure Cognitive Services Speech2Text\n",
    "  \n",
    "- Azure Cognitive Services Text2Speech\n",
    "\n",
    "- Azure Cognitive Services Text Analyics Health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acac096-2a0a-4997-9aa7-feb900c2e179",
   "metadata": {},
   "source": [
    "<b>For Windows/Linux users the package azure-ai-vision must be installed.\n",
    "Furthermore, an error will occur if a version is not supplied with it.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd574d-288b-4251-9622-4d3214a4f503",
   "metadata": {},
   "source": [
    "This is because azure-ai-vision has been yanked and is no longer supported. The package that has replaced it is <a>https://pypi.org/project/azure-ai-vision-imageanalysis/1.0.0b1/</a>. However, LangChain has not updated this and uses a deprecated package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def71058-e7d8-4133-baa6-c3646a42519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-formrecognizer\n",
    "!pip install azure-cognitiveservices-speech \n",
    "!pip install azure-ai-textanalytics\n",
    "\n",
    "#for Windows/Linux\n",
    "!pip install azure-ai-vision=='0.15.1b1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb6f0991-e1f2-4bfa-afa4-25ad0a8bb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import AzureCognitiveServicesToolkit\n",
    "from langchain.agents import AgentType, AgentExecutor, initialize_agent, create_structured_chat_agent\n",
    "#from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20933b9-277a-4bb4-b2dd-2d98b4642c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_COGS_KEY\"] = getpass.getpass()\n",
    "#os.environ[\"AZURE_COGS_ENDPOINT\"] = getpass.getpass()\n",
    "#os.environ[\"AZURE_COGS_REGION\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b98db77-bada-4b5a-bfc8-4a2a9a4bc0cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azure_cognitive_services_form_recognizer',\n",
       " 'azure_cognitive_services_speech2text',\n",
       " 'azure_cognitive_services_text2speech',\n",
       " 'azure_cognitive_services_text_analyics_health',\n",
       " 'azure_cognitive_services_image_analysis']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognitiveServices = AzureCognitiveServicesToolkit()\n",
    "[tool.name for tool in cognitiveServices.get_tools()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103473c-3a76-4a31-ad9e-29e43684549c",
   "metadata": {},
   "source": [
    "There are different types of agents that can be initialised, but we will be using the structured_chat_agent. It has 3 required parameters:\n",
    "\n",
    "- The model it will be using\n",
    "\n",
    "- The tool(s) it will be using\n",
    "\n",
    "- The prompt it will expect input to be formatted as and how it will be expected to format output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b8983c0-b05e-42ed-a79e-90b4c4db595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system = '''Transcribe the audio from input audio files to plain english text. You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "\n",
    "{{\n",
    "\n",
    "  \"action\": $TOOL_NAME,\n",
    "\n",
    "  \"action_input\": $INPUT\n",
    "\n",
    "}}\n",
    "\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "\n",
    "Thought: consider previous and subsequent steps\n",
    "\n",
    "Action:\n",
    "\n",
    "```\n",
    "\n",
    "$JSON_BLOB\n",
    "\n",
    "```\n",
    "\n",
    "Observation: action result\n",
    "\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "\n",
    "Thought: I know what to respond\n",
    "\n",
    "Action:\n",
    "\n",
    "```\n",
    "\n",
    "{{\n",
    "\n",
    "  \"action\": \"Final Answer\",\n",
    "\n",
    "  \"action_input\": \"Final response to human\"\n",
    "\n",
    "}}\n",
    "\n",
    "return the text transcribed from the audio.'''\n",
    "\n",
    "human = '''{input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "(reminder to respond in english text no matter what)\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Speech2text_tool = cognitiveServices.get_tools()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e0efc3e-ffe8-4441-a201-dad2ef19bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from langchainhub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spong\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.7.4)\n",
      "Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
      "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.20 types-requests-2.32.0.20240712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\spong\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\spong\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\spong\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71a47b35-bcae-4ea1-b721-b13806452b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6a0c9b8-d436-42ac-bc8b-21b90e7a42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = cognitiveServices.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7389da60-2c3d-4ac1-80fb-27383816ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AzureChatOpenAI(temperature=0)\n",
    "Speech2text_agent = create_structured_chat_agent(\n",
    "    tools=tools,\n",
    "    llm=model,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1be7b4c-4117-45d3-af93-5fae569a9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech2text_executor = AgentExecutor.from_agent_and_tools(agent = Speech2text_agent, tools=[])\n",
    "\n",
    "#Speech2text_executor.invoke({\"input\": \"What is the time?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af4c3c-0099-48b3-b75d-766ea21a8a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
